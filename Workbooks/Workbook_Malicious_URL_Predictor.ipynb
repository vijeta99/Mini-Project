{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workbook: Malicious URL Predictor",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NDweq7kqQXS",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning for Security Analysts - Workbook </br> Malicious URL Predictor\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Author: GTKlondike\n",
        "</br>\n",
        "Email: GTKlondike@gmail.com\n",
        "</br>\n",
        "YouTube: [NetSec Explained](https://www.youtube.com/channel/UCsKK7UIiYqvK35aWrCCgUUA)\n",
        "\n",
        "**Dataset:** https://github.com/NetsecExplained/Machine-Learning-for-Security-Analysts\n",
        "\n",
        "**Goal:** This workbook will walk you through the steps to build, train, test, and evaluate a malicious URL predictor using the Scikit-learn machine learning library\n",
        "\n",
        "**Outline:** \n",
        "* Initial Setup\n",
        "* Tokenization\n",
        "* Load Training Data\n",
        "* Vectorize Training Data\n",
        "* Load Testing Data\n",
        "* Train and Evaluate Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD52CaEDqSua",
        "colab_type": "text"
      },
      "source": [
        "## Instructions\n",
        "To use Jupyter notebooks:\n",
        "* To run a cell, click on the play button to the left of the code or pressh shift+enter\n",
        "* You will see a busy indicator in the top left area while the runtime is executing\n",
        "* A number will appear when the cell is done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWatBgyBZEZy",
        "colab_type": "text"
      },
      "source": [
        "# Initial Setup\n",
        "We'll start by downloading the data and loading the needed libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctfYiOVJ10FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download data from Github\n",
        "! git clone https://github.com/NetsecExplained/Machine-Learning-for-Security-Analysts.git\n",
        "  \n",
        "# Install dependencies\n",
        "! pip install nltk sklearn pandas matplotlib seaborn\n",
        "data_dir = \"Machine-Learning-for-Security-Analysts/Malicious URLs.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3llO4xb-eTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Common imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Import Scikit-learn helper functions\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "# Import Scikit-learn models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Import Scikit-learn metric functions\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n### Libraries Imported ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2Kzrx8970Zq",
        "colab_type": "text"
      },
      "source": [
        "# Load the dataset\n",
        "With this set, we first need to load our CSV data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6Cdtwmmd3w2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the training data\n",
        "print(\"- Loading CSV Data -\")\n",
        "url_df = pd.read_csv(data_dir)\n",
        "\n",
        "test_url = url_df['URLs'][4]\n",
        "\n",
        "print(\"\\n### CSV Data Loaded ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiEuaSS_8DuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's see what our training data looks like\n",
        "print(url_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWVv0Lzl8UXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform Train/Test split\n",
        "test_percentage = .2\n",
        "\n",
        "train_df, test_df = train_test_split(url_df, test_size=test_percentage, random_state=42)\n",
        "\n",
        "labels = train_df['Class']\n",
        "test_labels = test_df['Class']\n",
        "\n",
        "print(\"\\n### Split Complete ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb9tYHkw9JTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print counts of each class\n",
        "print(\"- Counting Splits -\")\n",
        "print(\"Training Samples:\", len(train_df))\n",
        "print(\"Testing Samples:\", len(test_df))\n",
        "\n",
        "# Graph counts of each class, for both training and testing\n",
        "count_train_classes = pd.value_counts(train_df['Class'])\n",
        "count_train_classes.plot(kind='bar', fontsize=16)\n",
        "plt.title(\"Class Count (Training)\", fontsize=20)\n",
        "plt.xticks(rotation='horizontal')\n",
        "plt.xlabel(\"Class\", fontsize=20)\n",
        "plt.ylabel(\"Class Count\", fontsize=20)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "count_test_classes = pd.value_counts(test_df['Class'])\n",
        "count_test_classes.plot(kind='bar', fontsize=16, colormap='ocean')\n",
        "plt.title(\"Class Count (Testing)\", fontsize=20)\n",
        "plt.xticks(rotation='horizontal')\n",
        "plt.xlabel(\"Class\", fontsize=20)\n",
        "plt.ylabel(\"Class Count\", fontsize=20)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXws95jzBpcC",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization\n",
        "Create our tokenizer by splitting URLs into their domains, subdomains, directories, files, and extensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp30x8Ropo_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define tokenizer\n",
        "#   The purpose of a tokenizer is to separate the features from the raw data\n",
        "\n",
        "\n",
        "def tokenizer(url):\n",
        "  \"\"\"Separates feature words from the raw data\n",
        "  Keyword arguments:\n",
        "    url ---- The full URL\n",
        "    \n",
        "  :Returns -- The tokenized words; returned as a list\n",
        "  \"\"\"\n",
        "  \n",
        "  # Split by slash (/) and dash (-)\n",
        "  tokens = re.split('[/-]', url)\n",
        "  \n",
        "  for i in tokens:\n",
        "    # Include the splits extensions and subdomains\n",
        "    if i.find(\".\") >= 0:\n",
        "      dot_split = i.split('.')\n",
        "      \n",
        "      # Remove .com and www. since they're too common\n",
        "      if \"com\" in dot_split:\n",
        "        dot_split.remove(\"com\")\n",
        "      if \"www\" in dot_split:\n",
        "        dot_split.remove(\"www\")\n",
        "      \n",
        "      tokens += dot_split\n",
        "      \n",
        "  return tokens\n",
        "    \n",
        "print(\"\\n### Tokenizer defined ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAJK7U4901sx",
        "colab_type": "text"
      },
      "source": [
        "## Task 1 - Tokenize a URL\n",
        "1. Print the full URL, **test_url**\n",
        "2. Print the results of **tokenizer(test_url)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-ZpjlF47Coq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's see how our tokenizer changes our URLs\n",
        "\n",
        "print(\"\\n- Full URL -\\n\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tokenize test URL\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJnB-FFwCKse",
        "colab_type": "text"
      },
      "source": [
        "# Vectorize the Data\n",
        "Now that the training data has been loaded, we'll train the vectorizers to turn our features into numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FpyYEaK0AXK",
        "colab_type": "text"
      },
      "source": [
        "## Task 2 - Train the vectorizers\n",
        "1. Create the count vectorizer **cVec** using the **CountVectorizer** function\n",
        "2. Configure *cVec* to use the *tokenizer* function from earlier\n",
        "3. Perform **fit_transform** on *cVec* to train the vectorizer with the *training URLs*\\\n",
        "a. Save the result as **count_X**\n",
        "\n",
        "\n",
        "4. Create the TF-IDF vectorizer **tVec** using the **TfidfVectorizer** function\n",
        "5. Configure *tVec* to use the *tokenizer* function from earlier\n",
        "6. Perform **fit_transform** on *tVec* to train the vectorizer with the *training URLs*\\\n",
        "a. Save the result as **tfidf_X** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAfNGyoMCRu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorizer the training inputs -- Takes about 30 seconds to complete\n",
        "#   There are two types of vectors:\n",
        "#     1. Count vectorizer\n",
        "#     2. Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "\n",
        "print(\"- Training Count Vectorizer -\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"- Training TF-IDF Vectorizer -\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# (Keep the following lines)\n",
        "print(\"\\n### Vectorizing Complete ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuOCCZ0N0ITx",
        "colab_type": "text"
      },
      "source": [
        "## Task 2a (optional) - Count the test URL tokens\n",
        "1. Print the count of each *token* from **test_url**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4LjPdSfEP5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Manually perform term count on test_url\n",
        "# (Write code here)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iT2Ymr90Ryr",
        "colab_type": "text"
      },
      "source": [
        "## Task 2b (optional) - View the test URL vectorizers\n",
        "1. Create a new **CountVectorizer** and **TfidfVectorizer** for demonstration\n",
        "2. Train the new vectorizers on **test_url** using **fit_transform**\n",
        "3. Print the results of each *transform*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjguwTHgDLBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\n- Count Vectorizer (Test URL) -\\n\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "# (Keep the following lines)\n",
        "print()\n",
        "print(\"=\" * 50)\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n- TFIDF Vectorizer (Test URL) -\\n\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzC_VgqEE7mh",
        "colab_type": "text"
      },
      "source": [
        "# Test and Evaluate the Models\n",
        "OK, we have our training data loaded and our testing data loaded. Now it's time to train and evaluate our models.\n",
        "\n",
        "But first, we're going to define a helper function to display our evaluation reports."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oybCUH9tzuJN",
        "colab_type": "text"
      },
      "source": [
        "## Task 3 - Vectorize the testing data\n",
        "1. Use **cVec** to *transform* **test_df['URLs']**\\\n",
        "a. Save the result as **test_count_X**\n",
        "\n",
        "2. Use **tVec** to *transform* **test_df['URLs']**\\\n",
        "a. Save the result as **test_tfidf_X**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYfQhPItHBjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorize the testing inputs\n",
        "#   Use 'transform' instead of 'fit_transform' because we've already trained our vectorizers\n",
        "\n",
        "print(\"- Count Vectorizer -\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"- TFIDF Vectorizer -\")\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n### Vectorizing Complete ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32pzJ3naFICU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define report generator\n",
        "\n",
        "def generate_report(cmatrix, score, creport):\n",
        "  \"\"\"Generates and displays graphical reports\n",
        "  Keyword arguments:\n",
        "    cmatrix - Confusion matrix generated by the model\n",
        "    score --- Score generated by the model\n",
        "    creport - Classification Report generated by the model\n",
        "    \n",
        "  :Returns -- N/A\n",
        "  \"\"\"\n",
        "  \n",
        "  # Generate confusion matrix heatmap\n",
        "  plt.figure(figsize=(5,5))\n",
        "  sns.heatmap(cmatrix, \n",
        "              annot=True, \n",
        "              fmt=\"d\", \n",
        "              linewidths=.5, \n",
        "              square = True, \n",
        "              cmap = 'Blues', \n",
        "              annot_kws={\"size\": 16}, \n",
        "              xticklabels=['bad', 'good'],\n",
        "              yticklabels=['bad', 'good'])\n",
        "\n",
        "  plt.xticks(rotation='horizontal', fontsize=16)\n",
        "  plt.yticks(rotation='horizontal', fontsize=16)\n",
        "  plt.xlabel('Actual Label', size=20);\n",
        "  plt.ylabel('Predicted Label', size=20);\n",
        "\n",
        "  title = 'Accuracy Score: {0:.4f}'.format(score)\n",
        "  plt.title(title, size = 20);\n",
        "\n",
        "  # Display classification report and confusion matrix\n",
        "  print(creport)\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "print(\"\\n### Report Generator Defined ###\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOMP_-ymzbuo",
        "colab_type": "text"
      },
      "source": [
        "## Task 4a - Train and evaluate the MNB-TFIDF model\n",
        "1. Create **mnb_tfidf** as a **MultinomialNB()** constructor\n",
        "2. Use **fit** to train *mnb_tfidf* on the training data (*tfidf_X*) and training labels (*labels*)\n",
        "3. Evaluate the model with the testing data (*test_tfidf_X*) and testing labels (*test_labels*):\\\n",
        "a. Use the **score** function in *mnb_tfidf* to calculate model accuracy; save the results as **score_mnb_tfidf**\\\n",
        "b. Use the **predict** function in *mnb_tfidf* to generate model predictions; save the results as **predictions_mnb_tfidf**\\\n",
        "c. Generate the confusion matrix with **confusion_matrix**, using the predictons and labels; save the results as **cmatrix_mnb_tfidf**\\\n",
        "d. Generate the classification report with **classification_report**, using the predictions and labels; save the results as **creport_mnb_tfidf**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_8Ii5LnFUMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Multinomial Naive Bayesian with TF-IDF\n",
        "\n",
        "# Train the model\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Test the mode (score, predictions, confusion matrix, classification report)\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "# (Keep the following lines)\n",
        "print(\"\\n### Model Built ###\\n\")\n",
        "generate_report(cmatrix_mnb_tfidf, score_mnb_tfidf, creport_mnb_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOYVD36UzYLp",
        "colab_type": "text"
      },
      "source": [
        "## Task 4b - Train and evaluate the MNB-Count model\n",
        "1. Create **mnb_count** as a **MultinomialNB()** constructor\n",
        "2. Use **fit** to train *mnb_count* on the training data (*count_X*) and training labels (*labels*)\n",
        "3. Evaluate the model with the testing data (*test_count_X*) and testing labels (*test_labels*):\\\n",
        "a. Use the **score** function in *mnb_count* to calculate model accuracy; save the results as **score_mnb_count**\\\n",
        "b. Use the **predict** function in *mnb_count* to generate model predictions; save the results as **predictions_mnb_count**\\\n",
        "c. Generate the confusion matrix with **confusion_matrix**, using the predictons and labels; save the results as **cmatrix_mnb_count**\\\n",
        "d. Generate the classification report with **classification_report**, using the predictions and labels; save the results as **creport_mnb_count**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOl4-P-vHy76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Multinomial Naive Bayesian with Count Vectorizer\n",
        "\n",
        "# Train the model\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Test the mode (score, predictions, confusion matrix, classification report)\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# (Keep the following lines)\n",
        "print(\"\\n### Model Built ###\\n\")\n",
        "generate_report(cmatrix_mnb_count, score_mnb_count, creport_mnb_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzpIslDdzVJh",
        "colab_type": "text"
      },
      "source": [
        "## Task 4c - Train and evaluate the LGS-TFIDF model\n",
        "1. Create **lgs_tfidf** as a **LogisticRegression()** constructor, using the **lbfgs** *solver*\n",
        "2. Use **fit** to train *lgs_tfidf* on the training data (*tfidf_X*) and training labels (*labels*)\n",
        "3. Evaluate the model with the testing data (*test_tfidf_X*) and testing labels (*test_labels*):\\\n",
        "a. Use the **score** function in *lgs_tfidf* to calculate model accuracy; save the results as **score_lgs_tfidf**\\\n",
        "b. Use the **predict** function in *lgs_tfidf* to generate model predictions; save the results as **predictions_lgs_tfidf**\\\n",
        "c. Generate the confusion matrix with **confusion_matrix**, using the predictons and labels; save the results as **cmatrix_lgs_tfidf**\\\n",
        "d. Generate the classification report with **classification_report**, using the predictions and labels; save the results as **creport_lgs_tfidf**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5x6-hlkItbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression with TF-IDF\n",
        "\n",
        "# Train the model\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Test the mode (score, predictions, confusion matrix, classification report)\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# (Keep the following lines)\n",
        "print(\"\\n### Model Built ###\\n\")\n",
        "generate_report(cmatrix_lgs_tfidf, score_lgs_tfidf, creport_lgs_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd2S7nCzzIpX",
        "colab_type": "text"
      },
      "source": [
        "## Task 4d - Train and evaluate the LGS-Count model\n",
        "1. Create **lgs_count** as a **LogisticRegression()** constructor, using the **lbfgs** *solver*\n",
        "2. Use **fit** to train *lgs_count* on the training data (*count_X*) and training labels (*labels*)\n",
        "3. Evaluate the model with the testing data (*test_count_X*) and testing labels (*test_labels*):\\\n",
        "a. Use the **score** function in *lgs_count* to calculate model accuracy; save the results as **score_lgs_count**\\\n",
        "b. Use the **predict** function in *lgs_count* to generate model predictions; save the results as **predictions_lgs_count**\\\n",
        "c. Generate the confusion matrix with **confusion_matrix**, using the predictons and labels; save the results as **cmatrix_lgs_count**\\\n",
        "d. Generate the classification report with **classification_report**, using the predictions and labels; save the results as **creport_lgs_count**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OTvv0tLItrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression with Count Vectorizer\n",
        "\n",
        "# Train the model\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Test the mode (score, predictions, confusion matrix, classification report)\n",
        "# (Write code here)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# (Keep the following lines)\n",
        "print(\"\\n### Model Built ###\\n\")\n",
        "generate_report(cmatrix_lgs_count, score_lgs_count, creport_lgs_count)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}